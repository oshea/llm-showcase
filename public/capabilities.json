[
  {
    "title": "Natural Language Understanding",
    "supported": ["GPT‚Äë4", "Claude", "Gemini"],
    "benchmarks": [
      { "name": "SuperGLUE (2019)", "url": "https://github.com/OpenBMB/ToolBench" },
      { "name": "GPQA (2023)", "url": "https://github.com/OpenBMB/ToolBench" },
      { "name": "MMLU-Pro (2024)", "url": "https://github.com/OpenBMB/ToolBench" },
      { "name": "HELM Capabilities (2025)", "url": "https://github.com/microsoft/API-Bank" }
    ],
    "rating": 4,
    "icon": "üîß",
    "useCase": "Ticket routing, email handling, sentiment analysis, chatbots, spam filtering, translation, knowledge management, search query understanding, document classification, information extraction from contracts, content moderation, research assistants.",
    "commentary": [
      "Natural-language understanding (NLU) is the capability that turns unstructured human text into structured facts a computer can act on‚Äîidentifying ‚Äúwho, what, when, where, why‚Äù in emails, reports, or chats. In effect, it gives software a tireless, reasonably accurate reader.",
      "The technology has matured to the point where, on widely accepted tests, leading models now perform at roughly human level for everyday language. Reliability drops only when the text becomes extremely technical, filled with equations, or heavy with domain-specific jargon; though there are solutions to address these.",
      "That means NLU can be woven into routine workflows with light oversight. Deploy it to do the heavy lifting, but gate low-confidence outputs for human review and add domain-specific tuning where specialized language appears. Regular fairness and robustness audits will keep the system aligned with policy and brand standards while allowing you to scale automation as the models continue to improve."
    ]
  },

    {
      "title": "Instruction Following",
      "supported": ["ChatGPT", "Gemini", "Claude", "Grok", "Deepseek"],
      "benchmarks": [
        { "name": "IFEval", "url": "https://arxiv.org/abs/2311.07911" },
        { "name": "FollowBench", "url": "https://arxiv.org/abs/2310.20410" },
        { "name": "MultiChallenge", "url": "https://arxiv.org/abs/2501.17399" },
        { "name": "CFBench", "url": "https://arxiv.org/abs/2408.01122" }
      ],
      "rating": 4,
      "icon": "llm-showcase/public/assets/IF.svg",
      "useCase": "Auto-generate a weekly financial report: Reads raw data, outputs Markdown with a brief summary (‚â§150 words), metrics table, formal tone, meeting all constraints perfectly on the first attempt.",
      "commentary": [
        "Accurately follow natural-language instructions, respecting all constraints (length, tone, format, content) on the first try. Understands intent, plans steps, and delivers precisely as requested.",
        "Precision is key for business value. LLMs are smart, but true impact comes from doing *exactly* what's asked. This cuts rework, reduces compliance risks, and accelerates workflows."
      ]
    },
    {
      "title": "Reasoning",
      "supported": ["GPT‚Äë4", "Claude", "Gemini"],
      "benchmarks": [
        { "name": "MMLU-Pro", "url": "https://github.com/openai/grade-school-math" },
        { "name": "HellaSwag", "url": "https://github.com/openai/grade-school-math" },
        { "name": "ARC-AGI", "url": "https://github.com/openai/grade-school-math" },
        { "name": "Humanity‚Äôs Last Exam", "url": "https://github.com/openai/grade-school-math" },
        { "name": "GPQA", "url": "https://github.com/openai/grade-school-math" },
        { "name": "Big-Bench Hard", "url": "https://github.com/google/BIG-bench" }
      ],
      "rating": 2,
      "icon": "üß†",
      "useCase": "Strategic decision support, automated prioritization, exception handling, scenario planning, trend interpretation, rule-based routing, anomaly flagging, risk assessment, performance evaluation, outcome forecasting.",
      "commentary": [
        "Reasoning lets software take a set of facts‚Äînumbers, rules, timelines, evidence‚Äîand work out what logically follows. Current models handle short, well-structured problems at human level, supplying quick answers to ‚Äúwhy‚Äù and ‚Äúwhat next‚Äù questions. Accuracy still slips on long, technical logic chains, so the capability remains in a mature-beta tier rather than full production.",
        "The safest approach is to use reasoning for first-pass analysis and decision support while keeping humans in the loop for outcomes that affect money, safety, or compliance. Break larger requests into smaller steps, track confidence scores, and route low-confidence results to reviewers. With those guardrails, teams gain faster insight and free up experts to focus on edge cases that machines still find hard."
      ]
    },
    {
      "title": "Planning",
      "supported": ["DALL-E 3", "Midjourney", "Stable Diffusion", "Gemini"],
      "benchmarks": [
        { "name": "PlanBench", "url": "https://parti.research.google/" },
        { "name": "AgentBench", "url": "https://parti.research.google/" },
        { "name": "AgentBoard", "url": "https://parti.research.google/" },
        { "name": "TaskBench", "url": "https://parti.research.google/" },
        { "name": "SafeAgentBench", "url": "https://cocodataset.org/" }
      ],
      "rating": 2,
      "icon": "üñºÔ∏è",
      "useCase": "Project-timeline drafting, marketing-campaign sequencing, DevOps incident runbook creation, travel or event itineraries, warehouse pick-and-place planning, supply-chain scheduling, meeting-room and resource booking flows, multi-tool business-process orchestration, robotics task sequencing, high-level product-roadmap creation.",
      "commentary": [
        "Planning lets an AI break a big goal into small, ordered steps, assess the impact of a step, and make adjustments until a job is complete. Along with reasoning, planning gives agents the ability to take on tasks to think more strategically.",
        "Today‚Äôs models do fine on short, tidy tasks, but they still drift or loop when the task is big or the world changes in mid-stream. So start small: give the agent a narrow set of tools, clear rules, and a tight space to work in. Log every action, set a hard step limit, and have a human ready to jump in if it stalls or gets confused. Break big projects into short sub-plans, and use classical schedulers or rule engines for parts that need exact answers (like truck routing or factory timing).",
        "If you treat the agent like a junior teammate‚Äîtrusted with well-defined chores, reviewed on tricky calls‚Äîyou‚Äôll see steady wins while the tech keeps improving over the next year."
      ]
    },
    {
      "title": "Computer Use",
      "supported": [
        "Operator",
        "Computer Use",
        "Specialized Agent Models"
      ],
      "benchmarks": [
        { "name": "WebArena", "url": "https://arxiv.org/abs/2307.13854" },
        { "name": "Mind2Web", "url": "https://arxiv.org/abs/2306.06070" },
        { "name": "OSWorld", "url": "https://arxiv.org/abs/2404.07972" },
        { "name": "WebVoyager", "url": "https://arxiv.org/abs/2401.13919" }
      ],
      "rating": 2,
      "icon": "llm-showcase/public/assets/CU.svg",
      "useCase": "Book a flight: Given 'Find cheapest direct LHR-JFK flight next Tuesday PM', agent opens site, searches, filters, selects best option, proceeds to booking (pausing for user confirmation).",
      "commentary": [
        "Lets AI agents understand instructions and operate GUIs (browsers, desktop apps) autonomously. Navigates websites, interacts with UI elements, extracts info, and completes multi-step tasks.",
        "Unlocks automation by letting AI *do* tasks. Potential to revolutionize workflows, accessibility, and assistance, though reliability across diverse interfaces is still improving."
      ]
    }
  ]